# Motivation

When users of CAD software construct models, they do it in whatever order is quickest. They do not generally draw connected segments or add constraints in any particular order.

Also, when thinking geometrically, users typically think about relationships between geometry. For example, these two lines are parallel. This line and this arc are tangent. They _don't_ typically think in terms of functions that compute the locations of points given other points.

In contrast, KCL of today has strict requirements of the order of things and how dependencies are defined. The equal length constraint in the Modeling App makes it so that the length of a segment is derived from the length of another segment. We require that users write expressions computing the derived value given the depended upon values. This means that paths must be constructed in a specific order that's a topological sort of dependencies. In particular, the first segment, which we'll call the root, cannot depend on any subsequent segments.

Additionally, KCL requires users to write functions that ultimately come down to computing the locations of points given other points. We have standard library functions that help make this somewhat higher-level, like `tangentialArc`, but it ultimately comes down to directly computing output locations based on inputs. This means that users must adapt their way of thinking to the tool rather than the tool adapting to them.

Notation: ||AB|| is defined as the length of the line segment between points A and B.

Example 1

Say that a user has a path A -> B -> C and wants to make ||AB|| be derived from ||BC||. The user must rewrite their code so that the path is constructed in a different way. A few options:

1. Reverse the order: C -> B -> A -- Requires rewriting delta expressions, e.g. angles are in the opposite direction.
2. Rotate the path: B -> C -> A -> B -- Only works for closed paths. It moves the root, but doesn't remove it.
3. Factor commonality out: `let x = common(); AB = segment1(x); BC = segment2(x)` -- `x` and `common` are likely very specific and can't be used anywhere else. `x` needs a name in the source, and it may not have much meaning on its own. Segment construction functions (`segment1` and `segment2` in this example) need to allow `x` to be an input. In the worst case, the implementation of `segment1()` might need to be: `if bar(x) { ... } else { ... }`. If we want to allow all this to happen with point-and-click, the app needs to understand how to write `common`, `segment1`, and `segment2` in terms of the original path expression. This seems non-trivial in the general case because anything that can be computed in stdlib functions must have a pure counterpart that can be used in `common`. `common` would ideally not have the side-effect of drawing to reduce ordering restrictions.

Example 2

Say that a user wants to construct a quadrilateral with ordered points A, B, C, and D such that ||CD|| is derived from ||AB|| and ||BC|| is derived from ||DA||. There are dependencies in both directions. Workarounds (1) and (2) above do not work since no single topological sort exists. The user _must_ factor out common expressions.

Factoring out code seems like a workaround for a fundamental limitation of KCL, relative to existing CAD software. Even when constraints are possible in KCL today, it requires that users write them down in a very specific way that isn't necessarily intuitive, even using non-visual linguistic mathematical reasoning.
# Proposal: A Constraint Language

A constraint in the mechanical engineering world is a mathematical relationship between two expressions. The user should be able to write these relationships in any order. The language implementation should treat these relationships as a system of constraints and solve for whatever derived values that are required to construct geometry. Derived values should not need to be expressed as the outputs of functions with known inputs if their relationship is determined by an equation that can be symbolically rearranged to the same thing.

As an example, we'll try to construct a sketch of a polygon where dependencies flow in both directions.

Note that the code is generated by the user clicking in the UI. The resulting code is in the order that it was created, meaning it's a history of actions that the user performed in the UI.

```
p1 = screen_point(x: 10, y: 12)
p2 = screen_point(x: 20, y: 13)
l1 = line(p1, p2)
p3 = screen_point(x: 21, y: 23)
l2 = line(p2, p3)
p4 = screen_point(x: 21, y: 23)
l3 = line(p3, p4)
l4 = line(p4, p1)
||l3|| = 0.5 * ||l1||^2
||l2|| = 1.2 * ||l4||
```

The above code can be read as follows:

1. User enters sketch mode, which defaults to line drawing.
2. User clicks a point. A variable `p1` is defined with the screen coordinates.
3. User clicks another point. A variable `p2` is defined at that point. Since they're in line-sketch mode, `l1 = line(p1, p2)` is also generated. The app knows to name it with the prefix `l` because it is generating the line, so it knows it's a line. Similarly with points.
4. Repeat the above for points `p3` and `p4`.
5. When they close the sketch by clicking `p1`, the app recognizes this, does not define a fifth point, and creates `l4 = line(p4, p1)`, closing the sketch.
6. The user selects one of the lines, clicks "Constrain length with function". This opens an input box in the command palette where the user can type an arbitrary expression.
7. The user types `0.5 * ||`, and the UI knows that the user wants to select a piece of geometry.
8. The user selects a line with their pointing device, and the app fills in `l1||`.
9. The user types `^2 Enter`, which finishes the expression.
10. At this point, the app appends at the end of the code the new line `||l3|| = 0.5 * ||l1||^2`.
	- Design note: We could add this relationship next to the definition of `l3`. This is a reasonable choice. But I think we should prefer to append to the end by default because it retains the history of user operations in the order that they did them, which can be useful when reading code. Not only do UI operations correspond one-to-one with lines of code (a spatial relationship), but they correspond in order to how the author created them (a temporal relationship). This strengthens the tie between the UI and code in the user's mind. If they find that they'd like a different order, they can reorder lines without affecting the meaning of the code in many cases. (We'll discuss exactly which cases later.)
11. Assume similar for `||l2||`.

## First-Class Points

Why name points instead of embedding the coordinates in the `line()` function calls? Mechanical engineers who are used to other CAD software expect to be able to create a point as standalone geometry. In this proposal, points are first-class. This has a few benefits:

1. It fits ME expectations better
2. It allows creating points that are used purely for construction (not display or manufacturing). For example, users can create other geometry derived from the point through relationships.
3. Named points are natural snap points in the point-and-click UI. Similar to how we use variable names to autocomplete in the editor, when the user is drawing, we can use named points as the set of points that a user might want to snap to, which is the point-and-click analogue of autocomplete.
4. It allows creating unconstrained points.
	1. In the above example, we used `p1 = screen_point(x: 10, y: 12)`, which is fully constrained to a coordinate relative to the screen's coordinate system.
	2. However, we could make an unconstrained point `p1 = point()`. This is still useful for constraining in code later.
	4. We could also make a point that's partially constrained `p1 = screen_point(y: 12)`. Note that this is constrained in the Y dimension, but not X, similar to current KCL's `yLine()` but for a point.
	5. Perhaps there could be other coordinate systems that users could define things in relation to. For example, maybe `p1 = printer_point(x: 10, y: 10)` indicates a point constrained relative to the printer bed's origin. When displaying this on the screen, we may move the printer bed within the screen's coordinate system, and the point would move with it.
	6. > Half-baked: It allows the runtime system to remove constraints without significant restructuring of the user's program. For example, say we wanted to display the geometry in a different coordinate system. We might transform all `screen_point()` constraints with a matrix, and nothing else needs to change. Or we might do symbolic manipulation, solving for unknowns without any concrete numbers.

## Parallel Lines Example

Say that a user wants to make a shape, but they don't want to author it in path-order. Currently, KCL requires users to construct a path by creating each segment in order in the UI. A user cannot create disconnected segments, add constraints to them, and then later join them.

In the proposed design, a user can do this.

```
// Create a line segment.
p1 = screen_point(x: 10, y: 12)
p2 = screen_point(x: 20, y: 13)
l1 = line(p1, p2)
// Create another, disconnected line segment.
p3 = screen_point(x: 21, y: 23)
p4 = screen_point(x: 22, y: 23)
l2 = line(p3, p4)
// Constrain the lines to be parallel.
parallel(l1, l2)
// Add a line segment connecting the others.
line(p2, p3)
```

In the standard library, we define `parallel`.

```
// Constrain two line parameters to be parallel.
constraint parallel(l1, l2) {
  v1 = vector_from_line(l1)
  v2 = vector_from_line(l2)
  vector_parallel(v1, v2) or vector_antiparallel(v1, v2)
}

// Return a 3D vector from a line.
fn vector_from_line(line) {
  return end_point(line) - start_point(line)
}

// Constrain two vectors to be parallel.
constraint vector_parallel(v1, v2) {
  dot(v1, v2) / (||v1|| * ||v2||) = 1
}

// Constrain two vectors to be antiparallel.
constraint vector_antiparallel(v1, v2) {
  dot(v1, v2) / (||v1|| * ||v2||) = -1
}

// Return the dot product between two 3D vectors.
fn dot(v1, v2) {
  return v1.x * v2.x + v1.y * v2.y + v1.z * v2.z
}
```

We introduced a new keyword `constraint` to indicate the effect of applying the function. `fn` is for defining pure, computational functions.

However, functions defined with `constraint` work a bit differently. When a user applies a `constraint`, instead of computing a value and returning it, the function applies constraints to its arguments. From the perspective of the caller, this may have the effect of mutating its input arguments, possibly filling in unknown values. Applications of `constraint` functions do not have a return value. They are more like rules in a logic programming language.

> Aside: In functional programming, we do not call functions; we apply them. When you write down a function, you're creating an abstraction. It's a template that is parameterized. When you fill in the parameter, you're applying the abstraction to specifics. On the other hand, "call" is something you do when you execute imperative commands. You call a subroutine and return from it.

The hope is that when a user applies `constraint`s to arguments, the arguments' unconstrained, and therefore unknown, values are filled in by the constraints.

In the case of `parallel(l1, l2)`, each line argument is made up of two points, each with three components, one for each dimension. So one way to think about it is that the caller is passing in two `struct`s with 6 unknowns each. And these unknowns may be filled in by the `constraint` application.

The points could also be partially constrained. I.e. the `constraint` may partially constrain values by adding relationships, but those relationships may not yet lead to fully constrained points. Additional constraints added in the future may fully constrain them.

## Discussion

### Using Constraints

When you want to construct geometry or define your own constraint functions, you write down a series of equations. These equations take the form:

```
<expression> <relational operator> <expression>
```

For example:

```
p1.x = 5
||l1|| = 2
2 * pi * my_radius < travel_length + tolerance
```

Unlike definitions or assignments in imperative or functional languages, constraints allow complex expressions on either side of the operator. Since they are mathematical relationships, the left-hand-side and right-hand-side can be swapped without changing the meaning, assuming you change the relational operator appropriately.
### Resolution Strategies

Sometimes, constraints can be ambiguous. Take this example:

```
travel_length = 10
tolerance = 0.03
my_radious > 0
2 * pi * my_radius < travel_length + tolerance
```

The implementation can symbolically solve for `my_radius`.

```
my_radius > 0
my_radius < (travel_length + tolerance) / (2 * pi)
```

Because `travel_length`, `tolerance`, and `pi` are known values, we can compute an upper and lower bound for `my_radius`.

However, `my_radius` is still not fully constrained. Therefore, we allow for resolution strategies.

```
travel_length = 10
tolerance = 0.03
my_radious > 0
2 * pi * my_radius < travel_length
maximize(my_radius)
```

By adding `maximize(my_radius)`, a specific value can be computed for `my_radius` even though it's not fully constrained. This is useful for displaying geometry that would only be partially constrained otherwise.

Resolution strategies are only used if values are not fully constrained otherwise. You can think of them as optional constraints. This is useful for library authors while writing constraint functions. Depending on what a constraint function is applied to, the result may or may not be fully constrained. Resolution strategies allow for a way to give hints to the runtime system that aren't strict requirements. I.e. resolution strategies will never cause geometry to be over-constrained. But they can help allow unconstrained or partially constrained geometry to become fully constrained.

> Half-baked: Initially, the only resolution strategies will be `minimize` and `maximize` to deal with inequalities. In future versions, we would allow users to define their own resolution strategies. The gist is that they need to define an implementation for a trait like this.

```
trait Resolve<T> {
  fn resolve(cs: Set<Constraint>) -> T
}
```

> It's parameterized with a type since a resolution strategy may only apply to numbers, for example, not vectors or lines. This is a very under-baked idea because if it's possible to define resolution strategies for composite types, multiple strategies could apply. How would we determine which ones to apply?
### Applying pure functions and constraints

At the top level of code, there's no use in applying pure functions.

```
dot(v1, v2)
```

This has no effect because `dot()` is a pure function. It computes the dot product of two vectors and returns it. The return value is ignored.

On the other hand, constraints are useful at the top level.

> Half-baked: Pure functions can use `constraint`s internally. However, any constraints built up do not escape the scope of the pure function. For this reason, a rule of thumb may be to only apply constraints to local variables, not parameters. But this is not a strict requirement. Any constraints applied to parameters are simply discarded before returning to the caller. Because it's defined in a pure function with `fn`, they follow the same lexical scoping rules. This is an under-baked idea because although this all sounds nice -- we don't want to create a split in the language where you can't use constraint code when writing a pure function -- it's unclear how this would be implemented. In theory, it could be as simple as cloning any input arguments, but I'm not sure how that works with the implementation discussed later.

### Displaying Geometry

Any geometry that is fully constrained will be shown by default. A user can opt-out of this using:

```
hide my_geometry
```

Similarly, you can be explicit that geometry should be shown.

```
show my_geometry
```

If `my_geometry` isn't fully constrained, it won't be shown. But if the program contains the above to explicitly show it, executing the program will result an error indicating that `my_geometry` can't be shown since it isn't fully constrained. The help message will display the names of geometry that aren't fully constrained, and optionally all the constraints that it does have. This way, the user can know where constraints need to be added in order to fully constrain the geometry.

`show` can generally be omitted for simple scripts or individual parts. However, it's critical for libraries or larger assemblies where program modification can cause geometry to unintentionally become partially constrained. In these cases, the user would want to be notified instead of geometry accidentally disappearing.

### Solver Hints

When users create complex relations, it may be outside of the ability of the implementation to solve for unknowns. Instead of restricting the types of relations that users can have, we give the user the ability to enter additional equations to allow fully constraining geometry.

For example, say the user wants to do this:

```
derivative(f, x) = 0
```

Depending on the abilities of the solver, it may not be able to meaningfully use this to constrain `x`. Similar to `unsafe` in Rust, `as` in TypeScript, or other languages where you can tell the system, "Trust me. I've verified this myself, and you can use it."

```
manually solve derivative(f, x) = 0 using {
  x = 2 * y - 1
}
```

The above is intentionally verbose and cumbersome in order to discourage its use. Similar to `unsafe` in Rust or `as` in TypeScript that disables certain checks that the language usually does, this tells the solver that when the first constraint is applied, it can optionally ignore the opaque constraint and use the additional constraints instead.
# Implementation

## Language

```
statement ::= r | decl | show e | hide e
relation ::= e | r rel_op r | minimize(e) | maximize(e)
relation_operator ::= `=` | `<` | `>` | `<=` | `>=` | `or`
declaration ::=
 | fn f(x0, ..., xn) { s0; ...; sn }
 | constraint c(x0, ..., xn) { s0, ..., sn }
expression ::=
 | n
 | un_op e
 | e bin_op e
 | x
 | e(e0, ...., en)
 | [e0, ..., en]
 | e[e]
 | { l0: e, ..., ln: e}
 | e.l
 | `manually solve` c0; ...; cn `using` { c0; ...; cn }
```

In terms of the language definition, resolution strategies are special built-in relations.

Negation is omitted from relation operators since this complicates the implementation.

Let-bindings for defining new variables are not statements. Instead, it's a relation that creates an equality constraint. There's no difference between defining a variable and creating an equality constraint.

Relations can use pure functions to constrain, and pure functions can use relations to constrain a value and return it. But pure functions cannot be used to constrain their arguments.
## Execution

As a user, you can think of execution as building up constraints, symbolic manipulation to solve for unknowns, resolution strategies, and numeric computation, in that order. Concrete numbers are only used in the last step.

However, the way this is actually implemented is by mapping language constructs to Datalog:

1. Numeric literals from the UI like `screen_point(x: 1, y: 2)` &rArr; Facts
2. Constraints &rArr; Rules

Datalog requires that rule arguments are of the form `p(x, y)`. It doesn't allow complex arguments such as `p(f(x), y)`. This means that when user code has an arbitrary equation, we'll need to symbolically solve for each variable to create valid Datalog rules.

Because we want to allow inequalities and disjunctions, we need these extensions in the Datalog engine.

Because Datalog allows rules and facts to be stated in any order, this language will generally allow statements to be in any order in the source.

Once we have a valid Datalog program, execution is computing the minimal Herbrand model. We can do this using a fixed-point algorithm.

> Half-baked: We should be able to do bottom-up, naive evaluation. We really need to test this for performance and expressivity. But I don't think we need queries. We actually want to compute the entire model so that we can display all fully constrained geometry. I could imagine some future where users might temporarily hide things in the UI. In this case, as an optimization, we might want to query only for the geometry we want to show. But I think this can be addressed in a future update.

Once this is done, all fully constrained geometry is displayed, unless it appears in `e` of a `hide e` statement. If `show e` appeared and `e` is not fully constrained, we display an error to the user.

When we determine that geometry should be displayed, we send it to the rendering engine. We cannot attempt to render before executing the entire user program because future constraints may over-constrain geometry, making it invalid. When geometry is determined to be over-constrained, an error message is displayed to the user, optionally showing all applicable constraints so that the user can fix their program.

If the rendering engine is remote, things like batching messages is not a concern because everything is sent in a single batch message. This obviously requires that we're actually able to compute geometry locally without the rendering engine.

# Future Work

> Half-baked: In addition to all the above benefits, my hope is that this system will be more amenable to automatic differentiation. Differentiation with respect to arbitrary design parameters is useful for sensitivity analysis. An example is a user designing an airplane wing. They may want to maximize lift-to-drag ratio with respect to design parameters like wing area or wing sweep. A properly designed system should be able to do this without resorting to executing the code with multiple concrete values and computing differences, which can be computationally expensive. This approach should be a last resort.
